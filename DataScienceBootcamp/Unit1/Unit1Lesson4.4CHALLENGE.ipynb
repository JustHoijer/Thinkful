{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to flex your critical evaluation skills. Read the following descriptions of an experiment and its analysis, identify the flaws in each, and describe what you would do to correct them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. The Sith Lords are concerned that their recruiting slogan, \"Give In to Your Anger,\" isn't very effective. Darth Vader develops an alternative slogan, \"Together We Can Rule the Galaxy.\" They compare the slogans on two groups of 50 captured droids each. In one group, Emperor Palpatine delivers the \"Anger\" slogan. In the other, Darth Vader presents the \"Together\" slogan. 20 droids convert to the Dark Side after hearing Palpatine's slogan, while only 5 droids convert after hearing Vader's. The Sith's data scientist concludes that \"Anger\" is a more effective slogan and should continue to be used.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that stands out to be in this experiment is the sample size, and with only one test it seems unreasonable to come to any concrete conclusion. Beyond that, I'd need additional information on the biases involved in the sampling procedure and the intention of people running the experiment. Questions like: What are the differences in the two groups of droids? (ex:were they captured differently) Were their other unaccounted for factors that led to more droids being converted from Emperor Palpatine? Is there a bias that favors the orginal slogan?. \n",
    "\n",
    "In terms of what I'd do differently; the first thing would be to run the experiment many more times. Some would be conducted in the same way, others would involve extraneous changes to the experiment methods. The changes would include altering which Sith Lord delivers each slogan, the number of droids in each sample, and combining/randomly selecting the captured droids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. In the past, the Jedi have had difficulty with public relations. They send two envoys, Jar Jar Binks and Mace Windu, to four friendly and four unfriendly planets respectively, with the goal of promoting favorable feelings toward the Jedi. Upon their return, the envoys learn that Jar Jar was much more effective than Windu: Over 75% of the people surveyed said their attitudes had become more favorable after speaking with Jar Jar, while only 65% said their attitudes had become more favorable after speaking with Windu. This makes Windu angry, because he is sure that he had a better success rate than Jar Jar on every planet. The Jedi choose Jar Jar to be their representative in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment I can see a glimse of Simpson's paradox. There is overt averaging across different groups without accounting for the differences in individual samples. Regardless of the results from each envoy, there will be demographic and systematic differences for each planet. With this experimenal procedure, it seems impossible to account for the untold effects the orginal attitude of the each planet is having on the survey results. Although Jar Jar Binks returned with more favorable results, there exists no evidence to deny the relative effectiveness of Mace Windu's effort. \n",
    "\n",
    "From a data perspective, I'd like more insight into how the surveys are being conducted. I'm suspicous of the innate percision possible when measuring something like \"more favorable attitudes\". I'm interested in things like: what are the measures of \"favorable\" and what are current attitudes being measured against?(I mean, is a 10% difference really meaningfull all things considered?). \n",
    "\n",
    "To improve on this experiement, I'd suggest some way of collecting data on each planet's attitudes before, during, and after the envoy's journey. This way there exists concrete baselines for the favorable influence on each individual planet. With an established metric for relative improvement, the results from each envoy can then be compared more fairly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. A company with work sites in five different countries has sent you data on employee satisfaction rates for workers in Human Resources and workers in Information Technology. Most HR workers are concentrated in three of the countries, while IT workers are equally distributed across worksites. The company requests a report on satisfaction for each job type. You calculate average job satisfaction for HR and for IT and present the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average job satisfaction calculated in this experiment is the average across different populations. This doesn't mean the results cannot provide some insight into the question being asked, but it cannot provide specific evidence for an action plan. If each work site was analysized individually, more insights could be drawn. An individual approach would allow the researcher to identify differences in job satisfaction for each job site, country, as well as for each IT and HR department. These types of results would lead to a much more valuable report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. When people install the Happy Days Fitness Tracker app, they are asked to \"opt in\" to a data collection scheme where their level of physical activity data is automatically sent to the company for product research purposes. During your interview with the company, they tell you that the app is very effective because after installing the app, the data show that people's activity levels rise steadily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that comes to mind in with this is the fact that their conclusion is based on comparing apples to oranges. The apple being people who install the app's activity levels, and the orange being people's activity levels who don't install the app or opt in to the data collection. The \"opt in\" data collection scheme also creates a potentially biased sample. It could lead to a systematic difference between the sample data and the population. Meaning that people who opt in could have different activity level than people who don't. Additionally, the cause of rising activity levels is not directly identifiable. It could be that people who install the tracker app are already steadily increasing their activity levels. \n",
    "\n",
    "To improve the significance of these results, I would suggest some method of comparing activity levels of people who do and do not install the app. Of course, the samples would need to be selected randomly from a consistent population. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. To prevent cheating, a teacher writes three versions of a test. She stacks the three versions together, first all copies of Version A, then all copies of Version B, then all copies of Version C. As students arrive for the exam, each student takes a test. When grading the test, the teacher finds that students who took Version B scored higher than students who took either Version A or Version C. She concludes from this that Version B is easier, and discards it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is a potentially funny thought experiment: the way the tests were distrubuted could have actually enabled students with version B to cheat more affectly than students with other versions. In this scenario, the order in which students came into the class would correspond with their sitting position; meaning the students sitting close to each other would have the same test version. Since version B would represent the middle of the class seating, it would mean these students have more access to other students with the same test than the students in the front and back of the class. This idea could account for the higher scores for version B. \n",
    "\n",
    "\n",
    "To prevent cheating, each version of the test should be distrubuted randomly. If that turned out to be the case, the conclusion that version B must me easier is still nsubstantiated. The statistics for these tests, regardless of version, is directly dependant on the the students taking them. Without accounting for the potential preformance of each student, there is no way of determining which test is easier. If it were permissable, determining which test is easiest could be done by having each student take all three versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
